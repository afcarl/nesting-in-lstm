{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy.stats import bernoulli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Configuration\n",
    "MAX_NESTING = 10\n",
    "BRANCHING = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language 1: Just (), exact nesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class L1():\n",
    "    def __init__(self, nest, branch):\n",
    "        #all possible symbold (excluding the terminator to have exact nesting)\n",
    "        self.lang_symbols = {i: \"(\"+(i+1)*\"S\"+\")\" for i in xrange(branch)}\n",
    "        self.lan_terminator = \"()\"\n",
    "        self.nesting = nest\n",
    "    \n",
    "    def generate_word(self):\n",
    "        curr_string = \"S\"\n",
    "        #only generate predetermined nestings (exactly this deeply nested)\n",
    "        for i in xrange(self.nesting):\n",
    "            #only if there are S to substitute\n",
    "            if curr_string.find(\"S\") != -1:\n",
    "                #split into substrings (so that you can generate different values for every occurence of S)\n",
    "                w =  [e+\"S\" for e in curr_string.split(\"S\")]\n",
    "                #remove the S from the last substring (it does not belong there)\n",
    "                w[-1] = w[-1][:-1]\n",
    "                #initialize the current string \n",
    "                curr_string = \"\"\n",
    "                for part_string in w:\n",
    "                    #generate substitution for every S\n",
    "                    new_part = part_string.replace(\"S\", random.choice(self.lang_symbols.values()))\n",
    "                    curr_string += new_part\n",
    "        #terminate string\n",
    "        return curr_string.replace(\"S\", self.lan_terminator)\n",
    "    \n",
    "    def generate_language(self, length):\n",
    "        return \" \".join([self.generate_word() for i in xrange(length)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((((((((((()))))))))))\n",
      "((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((()))))))))))\n"
     ]
    }
   ],
   "source": [
    "model = L1(MAX_NESTING, BRANCHING)\n",
    "print model.generate_word()\n",
    "print model.generate_language(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language 2: Just (), probablistic nesting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class L2():\n",
    "    def __init__(self, nest, branch):\n",
    "        #all possible symbold (excluding the terminator to have exact nesting)\n",
    "        self.lang_symbols = {i: \"(\"+i*\"S\"+\")\" for i in xrange(branch+1)}\n",
    "        self.lan_terminator = \"()\"\n",
    "        self.nesting = nest\n",
    "    \n",
    "    def generate_word(self):\n",
    "        curr_string = \"S\"\n",
    "        #only generate predetermined nestings (exactly this deeply nested)\n",
    "        for i in xrange(self.nesting):\n",
    "            #only if there are S to substitute\n",
    "            if curr_string.find(\"S\") != -1:\n",
    "                #split into substrings (so that you can generate different values for every occurence of S)\n",
    "                w =  [e+\"S\" for e in curr_string.split(\"S\")]\n",
    "                #remove the S from the last substring (it does not belong there)\n",
    "                w[-1] = w[-1][:-1]\n",
    "                #initialize the current string \n",
    "                curr_string = \"\"\n",
    "                for part_string in w:\n",
    "                    #generate substitution for every S\n",
    "                    new_part = part_string.replace(\"S\", random.choice(self.lang_symbols.values()))\n",
    "                    curr_string += new_part\n",
    "        #terminate string\n",
    "        return curr_string.replace(\"S\", self.lan_terminator)\n",
    "    \n",
    "    def generate_language(self, length):\n",
    "        return \" \".join([self.generate_word() for i in xrange(length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(())\n"
     ]
    }
   ],
   "source": [
    "model = L2(100, 1)\n",
    "print model.generate_word()\n",
    "#print model.generate_language(10000)\n",
    "#model_l1 = model.generate_language(10000000)\n",
    "#text_file = open(\"L1.txt\", \"w\")\n",
    "#text_file.write(model_l1)\n",
    "#text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((((()())(()()))((()())))(((()()))((()))))((((()())(()()))((()()))))) (((((()))((()())(()))))((((())(()())))(((()())(()()))((())(()()))))) (((((())(()()))((())(()())))(((())(()()))((()))))((((()()))))) (((((()())))(((()())(()()))((())(()()))))((((()))))) (((((()()))((()())(())))(((()()))))) (((((()())))(((()))((()())(()))))((((()())(()()))((()))))) (((((())))(((())(()))))((((())(()))((())(()))))) (((((()())(()))((())))(((()))((()()))))((((())(()()))((()())(()))))) (((((()())))(((())(()()))))((((())(()())))(((())(()()))((()())(()))))) (((((()())(()))((()())(()()))))((((()()))((()())))))\n"
     ]
    }
   ],
   "source": [
    "model = L1(5, 2)\n",
    "#print model.generate_word()\n",
    "print model.generate_language(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Language 3 - primitive Dyck Language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class L3():\n",
    "    def __init__(self, nest, prob_deeper):\n",
    "        #all possible symbold (excluding the terminator to have exact nesting)\n",
    "        self.lang_symbols = [\"\", \"(S)S\"]\n",
    "        self.lan_terminator = \"\"\n",
    "        self.nesting = nest\n",
    "        self.bern = bernoulli(prob_deeper)\n",
    "    \n",
    "    def generate_word(self):\n",
    "        curr_string = \"(S)S\"\n",
    "        #only generate predetermined nestings (exactly this deeply nested)\n",
    "        for i in xrange(self.nesting):\n",
    "            #only if there are S to substitute\n",
    "            if curr_string.find(\"S\") == -1:\n",
    "                break\n",
    "            #split into substrings (so that you can generate different values for every occurence of S)\n",
    "            w =  [e+\"S\" for e in curr_string.split(\"S\")]\n",
    "            w[-1] = w[-1][:-1]\n",
    "\n",
    "            #initialize the current string \n",
    "            curr_string = \"\"\n",
    "            for part_string in w:\n",
    "                #generate substitution for every S\n",
    "                new_part = part_string.replace(\"S\", self.lang_symbols[self.bern.rvs()])\n",
    "                curr_string += new_part\n",
    "        #terminate string\n",
    "        return curr_string.replace(\"S\", self.lan_terminator)\n",
    "    \n",
    "    def generate_language(self, length):\n",
    "        return \"\".join([self.generate_word() for i in xrange(length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'()(((((()())((((())()))((()))(())())))(()((((()))(()))())))(())(())((()((())())(())()))()()(()())(()))((()(((((())())(())))(()(())())()()()))()()()(()()())((())())(())())((((())(((())())(()))((())())(())())((((())())(()))((())())(()))()()(())())(((()(()))))((((())()))))((()(((())())(())())))'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L3(10, .75).generate_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_length_of_language(v):\n",
    "    base = 30000\n",
    "    if v==4:\n",
    "        return base * 40\n",
    "    elif v==5:\n",
    "        return base * 15\n",
    "    elif v==6:\n",
    "        return base * 5\n",
    "    elif v==7:\n",
    "        return base * 2\n",
    "    elif v==8:\n",
    "        return int(base * .6)\n",
    "    elif v==9:\n",
    "        return int(base * .2)\n",
    "    else:\n",
    "        return base\n",
    "    \n",
    "def create_lan_files():\n",
    "    for i in xrange(4,9):\n",
    "        print i+1\n",
    "        curr_chance = (i+1)/10.\n",
    "        model = L3(10, curr_chance)\n",
    "        fname = \"dyck-\" + str(curr_chance)+\".txt\"\n",
    "        lang = model.generate_language(get_length_of_language(i+1))\n",
    "\n",
    "        text_file = open(fname, \"w\")\n",
    "        text_file.write(lang)\n",
    "        text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##Language 4 - Dyck Language with 4 Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class L4():\n",
    "    def __init__(self, nest, prob_deeper):\n",
    "        #all possible symbold (excluding the terminator to have exact nesting)\n",
    "        self.lang_symbols = [\"[S]S\", \"(S)S\"]\n",
    "        self.lan_terminator = \"\"\n",
    "        self.nesting = nest\n",
    "        self.bern = bernoulli(prob_deeper)\n",
    "    \n",
    "    def generate_word(self):\n",
    "        curr_string = \"(S)S\"\n",
    "        #only generate predetermined nestings (exactly this deeply nested)\n",
    "        for i in xrange(self.nesting):\n",
    "            #only if there are S to substitute\n",
    "            if curr_string.find(\"S\") == -1:\n",
    "                break\n",
    "            #split into substrings (so that you can generate different values for every occurence of S)\n",
    "            w =  [e+\"S\" for e in curr_string.split(\"S\")]\n",
    "            w[-1] = w[-1][:-1]\n",
    "\n",
    "            #initialize the current string \n",
    "            curr_string = \"\"\n",
    "            for part_string in w:\n",
    "                #generate substitution for every S\n",
    "                new_sub = \"\"\n",
    "                if self.bern.rvs():\n",
    "                    new_sub = random.choice(self.lang_symbols)\n",
    "                new_part = part_string.replace(\"S\", new_sub)\n",
    "                curr_string += new_part\n",
    "        #terminate string\n",
    "        return curr_string.replace(\"S\", self.lan_terminator)\n",
    "    \n",
    "    def generate_language(self, length):\n",
    "        return \"\".join([self.generate_word() for i in xrange(length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'()(((([[[[[()][]]()[]][][()][]][(([])[])]()[[]]()]([]((())[])(())[]))[(([([])[]]()[])[(())[]](())[])[[[()]()][()][]]([[]]())()()])[[([((()))[()][]][[()][]][[]][])([[()]]([])[])[[()]()](())[]]][[[([[]]())[[]]()]((())())[()][]]][()[(())()][()]()]([(())[]]()[]))(((([[[]()](())][([])()]([])())([([])()]())((())[])[()][])(([(())[]](())[]))(((())[])([])[])[([])[]][[]]())[[[[[[]]()]]()[[]]()][((())())(())()][[()][]][()]()][([[()][]])([()]())[]()])()([(([()]())([])())[(())[]][[]]][(([])())[()][]]([()]())[()]())[[(([])[])([])][(())()][()]()][[[][]][[]][]]((())())[()])[]([([[][[[]][]](())]([[()][]][[]]()))([((())[])[[]]()]([[]][])([])())([[()][]][()]())[[()]][[]][]][]([((())[])([])()][(())()][[]][]))([[([([])()][()][])()[]()][[[()][]](())()][[[]]]][((([])())([])[])[(())()][[]][]][[([])()](())[]][[()][]]([]))(((([[]])[()][])([()]())([])())[[[[]][]][[]]]([][])()())(((([])())[[]][])(()())[()][])[][([])[]][()]()'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyck2 = L4(10, .9)\n",
    "dyck2.generate_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "def create_lan_files_L4():\n",
    "    for i in xrange(4,9):\n",
    "        print i+1\n",
    "        curr_chance = (i+1)/10.\n",
    "        model = L4(10, curr_chance)\n",
    "        fname = \"dyck2-\" + str(curr_chance)+\".txt\"\n",
    "        lang = model.generate_language(get_length_of_language(i+1))\n",
    "\n",
    "        text_file = open(fname, \"w\")\n",
    "        text_file.write(lang)\n",
    "        text_file.close()\n",
    "create_lan_files_L4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_test_L4():\n",
    "    \n",
    "    model = L3(10, .9)\n",
    "    fname = \"dyck2-\" + str(curr_chance)+\"-test.txt\"\n",
    "    lang = model.generate_language(1)\n",
    "\n",
    "    text_file = open(fname, \"w\")\n",
    "    text_file.write(lang)\n",
    "    text_file.close()\n",
    "create_test_L4()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
