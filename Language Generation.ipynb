{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy.stats import bernoulli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Configuration\n",
    "MAX_NESTING = 10\n",
    "BRANCHING = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language 1: Just (), exact nesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class L1():\n",
    "    def __init__(self, nest, branch):\n",
    "        #all possible symbold (excluding the terminator to have exact nesting)\n",
    "        self.lang_symbols = {i: \"(\"+(i+1)*\"S\"+\")\" for i in xrange(branch)}\n",
    "        self.lan_terminator = \"()\"\n",
    "        self.nesting = nest\n",
    "    \n",
    "    def generate_word(self):\n",
    "        curr_string = \"S\"\n",
    "        #only generate predetermined nestings (exactly this deeply nested)\n",
    "        for i in xrange(self.nesting):\n",
    "            #only if there are S to substitute\n",
    "            if curr_string.find(\"S\") != -1:\n",
    "                #split into substrings (so that you can generate different values for every occurence of S)\n",
    "                w =  [e+\"S\" for e in curr_string.split(\"S\")]\n",
    "                #remove the S from the last substring (it does not belong there)\n",
    "                w[-1] = w[-1][:-1]\n",
    "                #initialize the current string \n",
    "                curr_string = \"\"\n",
    "                for part_string in w:\n",
    "                    #generate substitution for every S\n",
    "                    new_part = part_string.replace(\"S\", random.choice(self.lang_symbols.values()))\n",
    "                    curr_string += new_part\n",
    "        #terminate string\n",
    "        return curr_string.replace(\"S\", self.lan_terminator)\n",
    "    \n",
    "    def generate_language(self, length):\n",
    "        return \" \".join([self.generate_word() for i in xrange(length)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((((((((((()))))))))))\n",
      "((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((())))))))))) ((((((((((()))))))))))\n"
     ]
    }
   ],
   "source": [
    "model = L1(MAX_NESTING, BRANCHING)\n",
    "print model.generate_word()\n",
    "print model.generate_language(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language 2: Just (), probablistic nesting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class L2():\n",
    "    def __init__(self, nest, branch):\n",
    "        #all possible symbold (excluding the terminator to have exact nesting)\n",
    "        self.lang_symbols = {i: \"(\"+i*\"S\"+\")\" for i in xrange(branch+1)}\n",
    "        self.lan_terminator = \"()\"\n",
    "        self.nesting = nest\n",
    "    \n",
    "    def generate_word(self):\n",
    "        curr_string = \"S\"\n",
    "        #only generate predetermined nestings (exactly this deeply nested)\n",
    "        for i in xrange(self.nesting):\n",
    "            #only if there are S to substitute\n",
    "            if curr_string.find(\"S\") != -1:\n",
    "                #split into substrings (so that you can generate different values for every occurence of S)\n",
    "                w =  [e+\"S\" for e in curr_string.split(\"S\")]\n",
    "                #remove the S from the last substring (it does not belong there)\n",
    "                w[-1] = w[-1][:-1]\n",
    "                #initialize the current string \n",
    "                curr_string = \"\"\n",
    "                for part_string in w:\n",
    "                    #generate substitution for every S\n",
    "                    new_part = part_string.replace(\"S\", random.choice(self.lang_symbols.values()))\n",
    "                    curr_string += new_part\n",
    "        #terminate string\n",
    "        return curr_string.replace(\"S\", self.lan_terminator)\n",
    "    \n",
    "    def generate_language(self, length):\n",
    "        return \" \".join([self.generate_word() for i in xrange(length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(())\n"
     ]
    }
   ],
   "source": [
    "model = L2(100, 1)\n",
    "print model.generate_word()\n",
    "#print model.generate_language(10000)\n",
    "#model_l1 = model.generate_language(10000000)\n",
    "#text_file = open(\"L1.txt\", \"w\")\n",
    "#text_file.write(model_l1)\n",
    "#text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((((()())))(((()()))))((((()())(())))(((())(()))((())(()()))))) (((((())(()()))))) (((((()())))(((())(()()))))) (((((()())(()()))((()()))))) (((((())))(((()()))((()))))) (((((())))(((()()))))) (((((()))))((((())(()())))(((()()))))) (((((()))((())))(((()())(()))))) (((((()))))((((()())(()()))))) (((((()()))((()())(()()))))((((())))))\n"
     ]
    }
   ],
   "source": [
    "model = L1(5, 2)\n",
    "#print model.generate_word()\n",
    "print model.generate_language(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Language 3 - primitive Dyck Language\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class L3():\n",
    "    def __init__(self, nest, prob_deeper):\n",
    "        #all possible symbold (excluding the terminator to have exact nesting)\n",
    "        self.lang_symbols = [\"\", \"(S)S\"]\n",
    "        self.lan_terminator = \"\"\n",
    "        self.nesting = nest\n",
    "        self.bern = bernoulli(prob_deeper)\n",
    "    \n",
    "    def generate_word(self):\n",
    "        curr_string = \"(S)S\"\n",
    "        #only generate predetermined nestings (exactly this deeply nested)\n",
    "        for i in xrange(self.nesting):\n",
    "            #only if there are S to substitute\n",
    "            if curr_string.find(\"S\") == -1:\n",
    "                break\n",
    "            #split into substrings (so that you can generate different values for every occurence of S)\n",
    "            w =  [e+\"S\" for e in curr_string.split(\"S\")]\n",
    "            w[-1] = w[-1][:-1]\n",
    "\n",
    "            #initialize the current string \n",
    "            curr_string = \"\"\n",
    "            for part_string in w:\n",
    "                #generate substitution for every S\n",
    "                new_part = part_string.replace(\"S\", self.lang_symbols[self.bern.rvs()])\n",
    "                curr_string += new_part\n",
    "        #terminate string\n",
    "        return curr_string.replace(\"S\", self.lan_terminator)\n",
    "    \n",
    "    def generate_language(self, length):\n",
    "        return \"\".join([self.generate_word() for i in xrange(length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(((((((((()())(()))(()())(())())())((((())())(())())()(())())()((())())(())())((()()))((()(())())(()())())(()(())())(()())(())())()()(())(()(())())((())()))(()(((()(()))((())())(())())(((())())(())())(()()))((((())())(()))((()))(())())((()())(())()))()()(())()((())())(()))((((()(((())()))((()))(())())((()()()))(((())())))(())())()()(()))(((((((()))(())()))()()(())()))((()(()()))())(()((())())()()))((()(()()()))((()(())()))(()(())())((())))(((((())())(())())((())()))(((())()))()(())())((((())())(())())((())())(())())(()(())())((())()))((((()((((())())(())()))(((()))))())))((()()()((()()))()(())())()(((((()))(())())()(())())(((())())()())((())())(())())((((())())(())))(((())()))(())()())()(())(((((())())()())()))()'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L3(10, .75).generate_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 29s, sys: 2.13 s, total: 2min 31s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "model = L3(10, .75)\n",
    "%time model_l1 = model.generate_language(30000)\n",
    "text_file = open(\"dyck.txt\", \"w\")\n",
    "text_file.write(model_l1)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
